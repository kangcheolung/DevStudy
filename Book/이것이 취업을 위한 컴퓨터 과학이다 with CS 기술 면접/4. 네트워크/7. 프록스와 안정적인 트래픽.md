# 프록스와 안정적인 트래픽

# 오리진 서버와 중간 서버: 포워드 프록시와 리버스 프록시

클라이언트와 서버 사이에는 수많은 네트워크 장비들이 있을 수 있고, 서버를 보완하는 수많은 중간 서버들도 있을 수 있습니다. 게다가 어느 한 서버에 문자가 생기더라도 문제없이 동작할 수 있도록 서버를 다중화하여 운영하는 경우도 많습니다. 

이때 수많은 네트워크 장비와 중간 서버들 사이에는 클라이언트가 최종적으로 메시지를 주고받는 대상, 즉 앞선 설명에서 단순히 ‘서버’라고 지칭했던 대상은 조금 더 정확히 표현하면 ‘자원을 생성하고 클라이언트에게 권한이 있는 응답을 보낼 수 있는 HTTP 서버’를 의미하는데, 이를 오리진 서버라고 합니다. 즉, 클라이언트와 오리진 서버 사이에는 많은 중간 서버가 있을 수 있습니다. 

## 프록시와 게이트웨이

대표적인 HTTP 중간 서버의 유형에는 포록시와 게이트웨이가 있습니다. 

### 프록시

프록시란 클라이언트가 선택한 메시지 전달의 대리자로, 주로 캐시 저장, 클라이언트 암호화 및 접근 제한 등의 기능을 제공합니다.  클라이언트가 어떤 프록시를 언제, 어떻게 사용할지 선택하기 때문에 프록시는 일반적으로 오리진 서버보다 클라이언트와 더 가까이 위치해 있습니다.

### 게이트웨이

게이트웨이는 오리진 서버들을 향하는 요청 메시지를 먼저 받아서 오리진 서버들에게 전달하는 문지기, 경비 역할을 수행합니다. 게이트웨이는 요청 메시지를 보내는 네트워크 외부의 클라이언트 시각에서 보면 마치 오리진 서버처럼 보입니다. 게이트웨이는 일반적으로 클라이언트보다 오리진 서버들에 더 가까이 위치해 있습니다. 

# 고가용성: 로드 밸런싱과 스케일링

## 가용성

주어진 특정 기능을 실제로 수행할 수 있는 시간의 비율을 가용성이라고 합니다. 업타임은 정상적인 사용 시간을 의미하고, 다운타임은 모종의 이유로 인해 정상적인 사용이 불가능한 시간을 의미합니다. 고가용성은 바로 이수식의 값이 높은 성질을 말합니다. 즉, 고가용성이란 전체 사용시간 중 대부분을 사용할 수 있는 특성을 말합니다. 

- 다운타임의 발생 이유
    
    다운타임의 발생 원인은 나열하기 어려울 정도로 다양합니다. 과도한 트래픽으로 인한 서비스 다운, 예기치 못한 소프트웨어 상의 오류 또는 하드웨어 장애가 원인일 수도 있고, 때로는 보안 공격이나 자연재해로 인해 발생할 수도 있습니다. 따라서 다운타임의 발생원인을 모두 찾아 원천 차단하기는 현실적으로 어려운 일입니다.
    

고가용성을 유지하는 것의 핵심은 ‘애초에 문제가 발생하지 않게 하는 것’이라기 보다는 ‘문제가 발생하더라도 계속 기능할 수도 있도록 설계하는 것’에 가깝습니다. 문제가 발생하더라도 기능할 수 있는 능력을 ‘’결함 감내’’라고 합니다. 이를 위한 대표적인 기술이 다중화입니다. 서버를 다중화하면 특정 서버에 문제가 발생하더라도 다른 예비 서버가 이를 대신해 동작할 수도 있기 때문입니다. 

## 로드 밸런싱

과도한 트래픽은 서버의 가용성을 떨어뜨립니다. 여기서 중요한 점은 서버를 다중화해도 이러한 문제가 발생하는 것은 마찬가지라는 점입니다. 서버를 다중화하더라도 특정 서버에만 트래픽이 몰린다면, 즉 트래픽이 고르게분산되지 않는다면 가용성을 떨어질 수 있습니다. 

따라서 하나 이상의 서버가 트래픽을 어떻게 고르게 분산하여 수신할지를 고려해야합니다. 트래픽의 고른 분배를 위해 사용되는 기술이 바로 로드 밸런싱입니다. 로드 밸런싱은 로드 밸런서에 의해 수행되는데, 로드 밸런서는 다중화된 서버와 클라이언트 사이에 위치하며 클라이언트의 요청들을 각 서버에 균등하게 분배하는 역할을 합니다. 

대표적인 로드 밸런싱 소프트웨어로는 HAProxy, Envoy 등이 있으며, 대표적인 웹 서버 소프트웨어인 Nginx 로드 밸런싱 기능이 내장되어 있습니다. 

로드 밸런서가 요청을 전달할 수 있는 서버가 여러 개일 경우 어떤 서버에 요청을 전달해야 할지를 결정하는 알고리즘, 즉 부하가 균등하게 분산되도록 요청을 전달할 서버를 선택하는 방법을 **“”로드 밸런싱 알고리즘””**이라고 합니다. 

대표적인 로드 밸런싱 알고리즘에는 단순히 서버를 돌아가며 부하를 전달하는 **“”라운드 로빈 알고리즘”**”과 연결이 적은 서버부터 우선적으로 부하를 전달하는 **“”최소 연결 알고리즘””**이 있습니다. 

로드 밸런싱에 있어 고려해야할 점이 하나 있습니다. 단순히 ‘다중화된 모든 서버에 균일한 부하를 부여하는’ 전략은 모든 서버의 성능이 동일하다는 전제가 있을 때만 유효하다는 것입니다. 

로드 밸런싱 알고리즘에는 이를 반영해 가중치가 부여될 수 있습니다. 즉, 각각의 알고리즘을 바탕으로 동작하되, 가중치가 높은 서버가 더 많이 선택되어 더 많은 부하를 받도록 할 수 있습니다. 

## 스케일링: 스케일 업 스케일 아웃 오토스케일링

서버 컴퓨터 혹은 그 서버 컴퓨터를 구성하는 부품, 네트워크 장비와 같은 인프라를 확정하거나 업그레이드하는 방법에는 크게 스케일 업과 스케일 아웃이 있습니다. 

### 스케일 업

스케일 업은 기존 부품을 더 나은 사양으로 교체하는 방법입니다. 스케일 업을 수직적 확장이라고도 부릅니다.

장점

설치와 구성의 단순함(쉽게 말해 더 좋은 장비로 갈아 끼우면 그만임)

단점

스케일 업은 스케일 아웃에 비해 유연하지 않다. 하나의 스케일 업 장비의 성능에 한계가 있을 경우, 스케일 아웃을 하지 않는 이상 계속해서 더 비싸고 성능 좋은 장비를 구비하는 수밖에 없기 때문이다. 

### 스케일 아웃

스케일 아웃은 기존 부품을 여러 개로 두는 방법입니다. 스케일 아웃을 수평적 확장이라고도 부릅니다. 

장점으로는 유연한 확장 및 축소가 가능하다는 점입니다. 스케일 업에 비해 설치와 구성이 단순하지 않을 수 있지만, 성치 및 구성 방법만 알면 장비의 확장과 축소가 매우 쉬워질 것입니다. 

무엇보다 스케일 아웃으로 확장할 경우, 스케일 업으로 확장했을 때보다 결함을 감내하기가 더 용이합니다. 스케일 업으로 확장했더라도 해당 장비가 하나밖에 존재하지 않는다면 해당 장비에 부하가 집중되거나 병목이 생길 우려가 있습니다. 반면, 스케일 아웃으로 확장하면 부하가 분산되도록 설계하기가 용이하기 때문에 병목이 생길 우려가 적어지므로 더욱 안정적인 운용이 가능합니다. 

# Nginx로 알아보는 로드 밸런싱

Nginx는 대표적인 웹 서버 프로그램입니다. Nginx는 앞서 학습한 포워드 프록시나 리버스 프록시로서의 기능도 제공합니다. Nginx 설치 이후에 간단한 설정만 하면 해당 호스트는 콘텐츠 캐싱, 보안을 위한 접근 제한, 로드 밸런싱 등이 가능합니다. 

Nginx를 설치하면 Nginx 설정 파일과 디렉터리들이 생성됩니다. 이 설정 파일과 디렉터리들은 Nginx가 어떤 상황에서 어떻게 동작할지를 정의합니다. 이들을 적절히 수정하면 Nginx가 설치된 호스트로 하여금 포워드 프록시 및 리버스 프록시의 역할을 수행하도록 할 수 있는 셈입니다. 

중요한 점

- 가장 기본적인 설정 파일이자 모든 설정들의 시작점이 되는 ${nginx}/nginx.conf 파일
- Nginx 관련 로그가 저장되는 ${nginx}/log/nginx/ 디렉터리
- 각종 설정 파일들이 포함되는 ${nginx}/conf.d/ 디렉터리