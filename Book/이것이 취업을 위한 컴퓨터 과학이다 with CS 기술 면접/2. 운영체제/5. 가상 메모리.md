# 가상 메모리

## 물리주소와 논리주소

CPU와 프로세스는 메모리의 하드웨어 상 실제 주소인 **“물리 주소”**가 아니라 다른 주소 체계인 논리 주소를 이용한다. **“논리 주소”**는 프로세스마다 부여되는 0번지부터 시작하는 주소 체계를 말한다. 가령 현재 메모리 상에 웹 브라우저, 메모장, 게임 프로세스가 적재되어 있다면 이 모든 프로세스에는 0번지부터 시작하는 각자의 논리 주소를 가지고 있는 셈이다. 

## 메모리 관리 장치(MMU)

논리 주소라 할지라도 실제로 정보가 저장되어 있는 하드웨어 상의 메모리와 상호작용하기 위해서는 반드시 논리 주소와 물리 주소간의 변환이 이루어져야한다. CPU는 논리 주소로 이야기하는데, 메모리가 물리 주소로 이야기한다면 서로 원활하게 통신하기 어렵기 때문이다. 
그래서 존재하는 하드웨어가 바로 **“메모리 관리 장치(MMU)”**이다. MMU는 CPU와 메모리 사이에 위치하며, CPU가 이해하는 논리 주소를 메모리가 이해하는 물리 주소로 변환하는 역할을 한다.  

## 스와핑과 연속 메모리 할당

### 스와핑

메모리에 적재된 프로세스 중에는 현재 실행되고 있지 않은 프로세스도 있을 수 있다. 입출력작업을 요구하며 대기 상태가 되었거나 오랫동안 사용되지 않은 프로세스가 이러한 프로세스에 해당된다. 이러한 프로세스들을 임시로 **“스왑 영역”**라는 보조기억장치의 일부인 영역으로 쫓아내고, 프로세스를 쫓아낸 자리에 생긴 메모리 상의 빈 공간에 다른 프로세스를 적재하여 실행하는 메모리 관리 방식을 **“스와핑”**이라고 한다. 

현재 실행되지 않은 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것을 **“스왑 아웃”,** 반대로 스왑 영역에 있는 프로세스가 다시 메모리로 옮겨지는 것을 **“스왑 인”**이라고 한다. 스왑 아웃되었던 프로세스가 다시 스왑 인될때는 스왑 아웃되기 전의 물리 주소와는 다른 주소에 적재될 수 있다. 

### 연속 메모리 할당과 외부 단편화

지금까지는 메모리 내에 프로세스들이 연속적으로 배치되는 상황을 가정했다. 예를 들자면 프로세스 A는 A의 크기만큼 메모리 주소를 할당 받아 배치되고, 프로세스 B는 프로세스 A 이후에 B의 크기만큼 연속적으로 메모리주소를 할당받아 배치되는 식의 방식이다. 이렇게 프로세스에 연속적인 메모리 공간을 할당하는 방식을 **“연속 메모리 할당”**이라고 한다. 

언뜻 보기에는 당연하고 보편적인 방식이라고 느낄 수 있지만, 사실 연속 메모리 할당은 메모리를 효율적으로 사용하는 방법은 아니다. 외부 단편화라는 문제를 내포하기 때문이다.  

프로세스들이 연속적으로 할당되는 환경에서는 프로세스의 실행과 종료를 반복하며 메모리 사이 사이에 빈 공간이 생긴다. 프로세스 바깥에 생기는 빈 공간들은 분명 빈 공간이 맞지만 그보다 큰 프로세스를 적재하기 어려운 상황을 초래하고, 이는 메모리 낭비로 이어진다. 이러한 현상을 **“외부 단편화”**라고 한다.

## 페이징을 통한 가상 메모리 관리

스와핑과 연속 메모리 할당은 2가지 문제가 내포한다. 첫 번째는 적재와 삭제를 반복하며 프로세스들 사이에 발생하는 외부 단편화이고, 또 하나는 물리 메모리보다 큰 프로세스를 실행할 수 없다는 문제이다. 

이러한 문제를 해결하는 운영체제의 메모리 관리 기술이 바로 가상 메모리이다. **“가상 메모리”**란 실행하고자 하는 프로그램의 일부만 메모리에 적재해, 실제 메모리보다 더 큰 프로세스를 실행할 수 있도록 만드는 메모리 관리 기법이다.  대표적인 가상 메모리 기법에는 **“페이징”**과 **“세그멘테이션”**이 있다. 

### 페이징

페이징은 프로세스이 논리 주소 공간을 페이지라는 일정한 단위로 나누고, 물리 주소 공간을 동일한 크기의 
**“프레임”**이라는 일정한 단위로 나눈 뒤 페이지를 프레임에 할당하는 가상 메모리 관리 기법이다.  이때 프로세스를 구성하는 페이지는 물리 메모리 내에 불연속적으로 배치될 수 있다는 점에 유의해야 한다. 

페이징 기법에서도 스와핑이 사용 될 수 있다. 페이징을 사용하는 시스템에서는 프로세스 전체가 스왑 아웃/ 스왑 인되는 것이 아니라 페이지 단위로 스왑 아웃/ 스왑 인된다. 

- 세그멘테이션
    
    세그멘테이션은 프로세스를 일정한 크기의 페이지 단위가 아닌 가변적인 크기의 세그먼트 단위로 분할하는 방식이다. 세그멘테이션 기법을 사용하면 세그먼트의 크기가 일정하지 않기 때문에 외부 단편화가 발생할 수 있다. 
    

### 페이지 테이블

앞서 프로시스를 구성하는 페이지는 물리 메모리 내에 불연속적으로 배치될 수 있다고 설명했다. 그런데 여기에는 문제가 있다. 물리 메모리 내에 페이지가 불연속적으로 배치되어 있다면, CPU 입장에서는 다음으로 실행할 페이지의 위치를 찾기가 어렵다. CPU가 프로세스를 이루는 어떤 페이지가 어떤 프레임에 적재되어 있는지를 모두 알고 있기는 어렵기 때문이다. 

이러한 문제를 해결하기 위해 프로세스의 페이지와 실재로 적재된 프레임을 짝지어주는 정보인 **“페이지 테이블”**을 활용한다.  페이지 테이블에는 페이지 번호와 실제로 적재된 프레임 번호가 대응되어 있다. 덕분에 CPU는 페이지 테이블의 페이지 번호만 보고도 적재된 프레임을 찾을 수 있다. 

## 페이지 테이블

페이지 테이블은 기본적으로 페이지 번호와 그에 대응되는 프레임 번호로 구성되어 있지만, 실은 기 이외에도 다른 중요한 정보들이 포함되어 있다. 페이지 테이블을 구성하는 각각의 행들을 “테이블 엔트리”라고 한다. 운영체제 마다 차이는 있지만, 페이지 테이블 엔트리에 포함되는 대표적인 정보로는 페이지 번호와 프레임 번호, 유호 비트, 보호 비트, 참조 비트, 수정 비트를 꼽을 수 있다. 

### 유호 비트

유호 비트는 해당 페이지에 접근이 가능한지 여부를 알려 주는 매우 중요한 정보이다. 유호 비트는 현재 페이지가 메모리, 아니면 보조기억장치에 적재되어 있는지 알려 주는 비트이다. 유호 비트는 페이지가 메모리에 적재되어 있다면 1, 페이지가 메모리에 적재되어 있지 않다면 0이 된다. 

만약 CPU가 메모리에 적재되지 않은 페이지, 즉 유호 비트가 0인 페이지에 접근하려고 하면 **“페이지 폴트”**라는 예외가 발생한다. 

### 보호 비트

보호 비트는 페이지 보호 기능을 위해 존재하는 비트이다. 읽기(Read)를 나타내는 r, 쓰기(Write)를 나타내는 w, 실행(eXecute)를 나타내는 x의 조합으로 페이지에 접근할 권한을 제한함으로써 페이지를 보호할 수 있다. 가령 보호 비트가 100이면 읽기만 가능하고, 111이면 읽기, 쓰기, 실행이 모두 가능하다. 

### 참조 비트

참조 비트는 CPU가 해당 페이지에 접근한 적이 있는지의 여불를 나타내는 비트이다. 페이지에 적재한 이후에 CPU가 읽거나 쓴 페이지는 참조 비트가 1로 설정되고, 적재한 이후에 한 번도 읽거나 쓴 적이 페이지는 0으로 유지된다. 

### 수정 비트

수정 비트는 해당 페이지에 데이터를 쓴 적이 있는지의 여부를 알려 주는 비트로, “더티 비트”라고도 부른다. 수정 비트가 1이면 변경된 적이 있는 페이지고, 0아면 변경된 적이 없는 페이지임을 나타낸다. 

### 내부 단편화

페이징은 외부 단편화 문제를 해결할 수 있지만, 내부 단편화라는 또 다른 문제를 여기할 수 있다. 페이징은 프로세스의 논리 주소 공간을 페이지라는 일정하 크기의 단위로 나누는 방식이지만, 모든 프로세스가 페이지 크기에 딱 맞게 잘리는 것이 아니다. 이렇게 페이지 하나의 크기보다 작은 크기로 발생하게 되는 메모리 낭비를 “내부 단편화”라고 한다. 

### 페이지 테이블 베이스 레지스터

각 프로세스의 페이지 테이블은 메모리에 적재될 수 있다. 따라서 어떤 프로세스를 실행하려면 이 프로세스의 페이지 테이블이 메모리에 적재된 위치를 알아야 한다. 특정 프로세스의 페이지 테이블이 적재된 메모리 상의 위치를 가리키는 특별한 레지스터가 있는데 바로 “페이지 테이블 베이스 레지스터”이다. PTBR은 프로세스 마다 가지는 정보이므로 각 PCB에 기록되며, 다른 프로세스로의 문맥 교환이 발생할 때 변경된다. 

앞서 페이지 테이블에 적재될 수 있다라고 표현한 이유가 있다. 모든 프로세스의 페이지 테이블을 메모리에 두는 것은 “1. 메모리 접근횟수가 많아지고”, “2. 메모리 용량을 많이 차지하기 때문에 비효율적이다”. 1과 2, 각각의 문제 상황과 해결 방법에 대해 좀 더 알아보겠다. 

### 메모리 접근 횟수

모든 프로세스의 페이지 테이블이 메모리에 적재되어 있을 경우, CPU는 페이지 테이블에 접근하기 위해 한 번, 실제 프레임에 접근하기 위해 한 번, 이렇게 총 두 번 메모리에 접근해야 한다. 따라서 메모리에 접근하는 시간이 두 배로 늘어날 수 있다. 이를 해결하기 위해 “TLB”란 페이지 테이블의 캐시 메모리가 사용된다. TLB는 페이지 테이블의 캐시이므로 참조 지역성의 원리에 근거해 자주 사용할 법한 페이지 위주로 페이지 테이블의 일부 내용을 저장한다. 

- TLB 히트: CPU가 접근하려는 논리 주소의 페이지 번호가 TLB에 있을 경우, TLB는 CPU에게 해당 페이지 번호가 적재된 프레임 번호를 알려준다. 이를 TLB 히트라고 한다
- TLB 미스: 페이지 번호가 TLB에 없는 경우에는 어쩔 수 없이 페이지가 적재된 프레임을 알기 위해 메모리내의 페이지 테이블에 접근하는 수 밖에 없다. 이를 TLB 미스라고 한다.

### 메모리 용량

페이지 테이블의 크키는 생각보다 작지 않다. 프로세스의 크기가 커지면 자연히 페이지 테이블의 크기도 커지기 때문에 프로세스를 이루는 모든 페이지 테이블 엔트리들을 메모리에 두는 것은 큰 메모리 낭비이다. 그래서 등장한 방법 중 하나가 계층적 페이징이다. “계층적 페이징”은 페이지 테이블을 페이징하는 방식으로, 여러 단계의 페이지를 둔다는 점에서 다단계 페이지 테이블 기법이라고도 부른다. 

### 페이징 주소 체계

하나의 페이지 내에는 여러주소가 포함되어 있기 때문에 페이징 시스템의 논리 주소는 기본적으로 <페이지 번호, 변위>와 같은 형태로 이루어져 있다. “페이지 번호”는 몇 번째 페이지 번호에 접근할지를 나타낸다. 페이지 테이블을 참조하면 물리 메모리 내의 어떤 프레임에 접근할지를 알 수 있다. 

또한 “변위”는 접근하랴는 주소가 페이지 시작 번지로부터 얼만큼 떨어져 있는지를 나타내는 정보이다. 

## 페이징 교체 알고리즘

메모리에 프로세스를 적재할 때 처음부터 모든 페이지를 적재하지 않고, 메모리에 필요한 페이지만을 적재하는 기법을 요구 페이징이라고 한다. 요

- 요구 페이징의 기본 양상
    1. CPU가 특정 페이지에 접근하는 명령어를 실행한다. 
    2. 해당 페이지가 현재 메모리에 있을 경우 CPU는 패이지가 적재된 프레임에 접근한다. 
    3. 해당 페이지가 현재 메모리에 없는 경우 페이지 폴트가 발생한다. 
    4. 페이지 폴트가 발생하면 페이지 폴트 처리 루틴을 통해 해당 페이지를 적재하고, 유효 비트를 1로 설정한다. 
    5. 다시 1의 과정을 수행한다. 

참고로, 아무런 페이지도 메모리에 적재하지 않은 채 무작정 프로세스를 실행할 수도 있다. 이를 **“순수 요구 페이징”**이라고 한다. 순수 요구 페이징일 경우 프로세스의 첫 명령어를 실행하는 순간부터 페이지 폴트가 발생하게 되고, 실행에 필요한 페이지가 어느 정도 적재된 이후부터는 페이지 폴트의 발생 빈도가 떨어진다. 

메모리에 페이지가 가득찬 상황에서는 추가적으로 페이지를 적재해야한다면 메모리에 적재된 일부 페이지를 스왑 아웃해야 한다. 이때 메모리에 적재된 페이지 중 보조기억장치로 내보낼 페이지를 선택하는 방법을 “**페이지 교체 알고리즘”**이라고 한다. 

### FIFO 페이지 교체 알고리즘

FIFO 페이지 교체 알고리즘은 이름 그대로 메모리에 가장 먼저 적재된 페이지부터 스왑 아웃하는 페이지 교체 알고리즘이다. 아이디어 구현은 간단하지만, 초기에 적재되어 줄곧 참조되고 있는 페이지를 스왑 아웃할 우려가 있다. 

### 최적 페이지 교체 알고리즘

최적 페이지 교체 알고리즘은 앞으로의 사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘이다. 메모리에 적재된 페이지들 중 앞으로 가장 적게 사용할 페이지를 스왑 아웃해 가장 낮은 페이지 폴트율을 보장하는 알고리즘이다. 이름 그대로 최적의 알고리즘이라고 할 수 있지만, 미리 예측 가능하기가 어렵기 때문에 실제 구현이 어려운 알고리즘이다. 

### LRU 페이지 교체 알고리즘

LRU 페이지 교체 알고리즘은 가장 적게 사용한 페이지를 교체하는 알고리즘이다. 보편적으로 사용되는 페이지 교체 알고리즘의 원형이며, 이를 기반으로 만들어진 다양한 파생 알고리즘이 있다.